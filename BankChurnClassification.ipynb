{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Binary Classification with a Bank Churn Dataset\n",
        "Objective of this model is to predict whether a customer continues with their account or closes it (e.g., churns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "b64CKvIcJW2w"
      },
      "outputs": [],
      "source": [
        "# One-time setup\n",
        "# ! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t68JGwawJTIu"
      },
      "source": [
        "Install dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx-c86f2JKsU",
        "outputId": "66905e98-6c7e-4e72-f532-e901857bd686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "playground-series-s4e1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  playground-series-s4e1.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "! kaggle competitions download -c playground-series-s4e1\n",
        "! unzip playground-series-s4e1.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-lwJUzb_e3z"
      },
      "source": [
        "First, let's import training data. Before we continue, we perform some data pre-processing. In our data, we have columns of non-numerical data. We drop irrelevant ones and one-hot encode ones that do. Then, we scale numerical features as they originally consist of different ranges. We then finally allocate 20% of training data for validation testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "O_4tikbk79Hc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "train_data_path = './train.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Drop irrelevant columns (id, CustomerId, Surname)\n",
        "train_data = train_data.drop(columns=[\"id\", \"CustomerId\", \"Surname\"])\n",
        "\n",
        "# one-hot encode categorical variables\n",
        "train_data = pd.get_dummies(train_data, columns=[\"Geography\", \"Gender\"])\n",
        "\n",
        "# Seperate features and labels\n",
        "train_labels = train_data[\"Exited\"]\n",
        "train_data = train_data.drop(columns=[\"Exited\"])\n",
        "\n",
        "# Normalize/Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(train_data_scaled, train_labels, test_size=0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g97Dyh8kT16L"
      },
      "source": [
        "We perform the same pre-processing to the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcvIpIq4T6tL"
      },
      "outputs": [],
      "source": [
        "# Pre-process test data as well\n",
        "test_data_path = './test.csv'\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "test_data = test_data.drop(columns=[\"id\", \"CustomerId\", \"Surname\"])\n",
        "test_data = pd.get_dummies(test_data, columns=[\"Geography\", \"Gender\"])\n",
        "\n",
        "y_test = test_data[\"Exited\"]\n",
        "X_test = test_data.drop(columns=[\"Exited\"])\n",
        "\n",
        "X_test = scaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oftMbQ8vIMzg"
      },
      "source": [
        "Now, define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b__31XgRITRM"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
